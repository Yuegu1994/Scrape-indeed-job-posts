{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect jobs descriptions, practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from bs4) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4  \n",
    "# install beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from requests) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yuegu1994\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'https://uk.indeed.com/jobs?q={}&l={}'\n",
    "\n",
    "# example1 = https://uk.indeed.com/jobs?q=data%20analyst&l=United%20Kingdom&vjk=3cdc735c12c5b93e\n",
    "# example2 = https://uk.indeed.com/jobs?q=Data%20Scientist&l=United%20Kingdom&vjk=7e63bd66d4927fab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a funtion for URL which is a funtion of position(occupation) and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    \"\"\" Generate  a url from position and location\"\"\"\n",
    "    template = 'https://uk.indeed.com/jobs?q={}&l={}'\n",
    "    url = template.format(position, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://uk.indeed.com/jobs?q=data analyst&l=United Kingdom\n"
     ]
    }
   ],
   "source": [
    "url = get_url('data analyst','United Kingdom')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "# Response [200] means the request is succesful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "?BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>hCaptcha solve page</title>\n",
       "<script async=\"\" defer=\"\" src=\"https://www.hcaptcha.com/1/api.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<form action=\"/jobs?q=data%20analyst&amp;l=United%20Kingdom\" method=\"POST\">\n",
       "<div class=\"h-captcha\" data-sitekey=\"eb27f525-f936-43b4-91e2-95a426d4a8bd\"></div>\n",
       "<br/>\n",
       "<input type=\"submit\" value=\"Submit\"/>\n",
       "</form>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = soup.find_all('div','job_seen_beacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-acb83bce4ec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Job title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcard\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Job title \n",
    "card =  cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card.find('h2', 'jobTitle').span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card.find('h2', 'jobTitle jobTitle-newJob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atag = card.find('h2', 'jobTitle').span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atag['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = atag.get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card.find('span','companyName').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = card.find('span','companyName').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card.find('div','companyLocation').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = card.find('div','companyLocation').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card.find('span','date').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_date = card.find('span','date').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_salary = card.find('div','metadata salary-snippet-container').text.strip()\n",
    "except AttributeError:\n",
    "    job_salary = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the model with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"  \n",
    "    atag = card.find('h2', 'jobTitle').span\n",
    "    if atag.get('title') is not None:\n",
    "        job_title = atag.get('title')\n",
    "    elif atag.get('title') is None and card.find('h2', 'jobTitle jobTitle-newJob').span.get('title') is not None:\n",
    "        job_title = card.find('h2', 'jobTitle jobTitle-newJob').span.get('title')\n",
    "    else:\n",
    "        job_title = ''\n",
    "    company = card.find('span','companyName').text.strip()\n",
    "    job_location = card.find('div','companyLocation').text\n",
    "    post_date = card.find('span','date').text\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    try:\n",
    "        job_salary = card.find('div','metadata salary-snippet-container').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    ## assign the data into a tuple\n",
    "    record = (job_title, company, job_location, post_date, today, job_salary)\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for i in cards:\n",
    "    record = get_record(i)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = 'https://www.indeed.com' + soup.find('a',{'aria-label':'Next'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    cards = soup.find_all('div','job_seen_beacon')\n",
    "    \n",
    "    for card in cards:\n",
    "        record = get_record(card)\n",
    "        records.append(record)\n",
    "\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put it all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "import csv\n",
    "\n",
    "# create a function generating the website url based on position and location\n",
    "def get_url(position, location):\n",
    "    \"\"\" Generate  a url from position and location\"\"\"\n",
    "    template = 'https://uk.indeed.com/jobs?q={}&l={}'\n",
    "    url = template.format(position, location)\n",
    "    \n",
    "    return url\n",
    "\n",
    "# generate a function extracting key information from the job post Card\n",
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    atag = card.find('h2', 'jobTitle').span\n",
    "    if atag.get('title') is not None:\n",
    "        job_title = atag.get('title')\n",
    "    else:\n",
    "        job_title = ''\n",
    "    try:\n",
    "        company = card.find('span','companyName').text.strip()\n",
    "    except AttributeError:\n",
    "        company = ''\n",
    "    job_location = card.find('div','companyLocation').text\n",
    "    post_date = card.find('span','date').text\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    try:\n",
    "        job_salary = card.find('div','metadata salary-snippet-container').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    ## assign the data into a tuple\n",
    "    record = (job_title, company, job_location, post_date, today, job_salary)\n",
    "    \n",
    "    return record\n",
    "     \n",
    "\n",
    "def main(position, location):\n",
    "    records = []\n",
    "    # define the initial url\n",
    "    url = get_url(position,location)\n",
    "\n",
    "    while True:\n",
    "    # while True means loop forever\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('div','job_seen_beacon')\n",
    "\n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    " \n",
    "        try:\n",
    "            url = 'https://uk.indeed.com' + soup.find('a',{'aria-label':'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "   \n",
    "    # save the data in a csv file\n",
    "    with open('result.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['JobTitle','Company','Location','PostDate','ExtractDate','Salary'])\n",
    "        writer.writerows(records)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = main('data analyst', 'United Kingdom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
